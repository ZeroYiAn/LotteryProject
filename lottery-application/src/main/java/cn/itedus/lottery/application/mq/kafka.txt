1.为什么选择Kafka？
kafka技术成熟，具有每秒十万级别的高吞吐量，消息延迟低，可用性很高（自身分布式，集群结构的特点）

Apache Kafka是一个分布式发布 - 订阅消息系统和一个强大的队列，可以处理大量的数据，并使您能够将消息从一个端点传递到另一个端点。 Kafka适合离线和在线消息消费。 Kafka消息保留在磁盘上，并在群集内复制以防止数据丢失。 Kafka构建在ZooKeeper同步服务之上。 它与Apache Storm和Spark非常好地集成，用于实时流式数据分析。
以下是Kafka的几个好处：

可靠性 - Kafka是分布式，分区，复制和容错的。
可扩展性 - Kafka消息传递系统轻松缩放，无需停机。
耐用性 - Kafka使用分布式提交日志，这意味着消息会尽可能快地保留在磁盘上，因此它是持久的。
性能 - Kafka对于发布和订阅消息都具有高吞吐量。 即使存储了许多TB的消息，它也保持稳定的性能。

Kafka非常快，并保证零停机和零数据丢失


2.怎么解决kafka消息丢失问题？
a) 生产者数据丢失： 在发送消息时添加回调函数，判断消息是否发送成功，并对发送失败的消息采取相应补偿措施：如消息重发

本项目中通过数据库中的mq_state字段来判断消息是否发送成功，对发送失败的消息通过任务调度中心进行扫描补偿


b) 消费者数据丢失：手动提交offset偏移量，kafka会记录自己消费的offset数值，下次消费时会接着上次的offset进行消费
（由于offset信息的写入并不是每条消息消费完成后写入的，有可能写入了offset但是消息还没消费掉，于是这种方法可能会造成重复消费）

c) broker数据丢失，每个broker中的partition一般设置有若干副本replication，生产者写入根据分发策略写入到leader中，在把数据
备份同步到副本follow中，保证消息数据不丢失
基于kafka的ack机制，kafka发送数据时有一个确认反馈机制，确保消息能把正常收到，其状态有0，1，-1三种
要保证数据严格不丢失的话：
       --- 同步模式：ack设置为-1(all)即可
       --- 异步模式：ack设置为-1(all)，并把buffer(控制数据的发送)设置成-1，永久堵塞直到缓冲区可用，buffer满了数据也不会发送

3.怎么解决kafka消息重复的问题？
--- 消费消息时做幂等性校验，比如Redis的set、MySQL的主键等天然幂等功能




4.如何保证消息的有序？
由于kafka只能(通过offset)保证同一Partition(分区)中的消息有序
所以一种简单的方式是：1个topic只对应一个Partition(分区)，但是这样做就没能利用到kafka的架构优势

方法2：发送消息时，通过指定key 或者 Partition(分区)，把消息发送到指定的分区即可